{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d14fe0e9",
   "metadata": {},
   "source": [
    "# 次回の範囲\n",
    "2章の最後まで\n",
    "\n",
    "#### 基本\n",
    "- 2.3.6.1(PDF96枚目)のランダムフォレストを読む(PDF101枚目まで)．\n",
    "- ランダムフォレストを実行する（PDF99枚目）．\n",
    "- まとめと展望を読む（PDF138 - 140）．\n",
    "\n",
    "#### 推奨\n",
    "- 全て読む(PDF140枚目まで)．ニューラルネットワークは読まなくてもいいかも．\n",
    "- ランダムフォレスト，勾配ブースティング回帰木，SVMを実行する．\n",
    "\n",
    "#### 挑戦\n",
    "- タイタニックやってみる（https://www.kaggle.com/c/titanic）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0135c9bf",
   "metadata": {},
   "source": [
    "# 今回の範囲\n",
    "2章の線形モデルまで\n",
    "\n",
    "#### 基本\n",
    "- 最初のp. 27（PDF41枚目）から2.2(PDF45枚目)までを読む．\n",
    "- k-近傍回帰の実装，つまりPDF57枚目から58枚目のR<sup>2</sup>の算出までをGit Hubのコピペでもいいので実行する．\n",
    "- 2.3.3.3のリッジ回帰（PDF64枚目）をGitHubのコピペでもいいので実行する．\n",
    "\n",
    "#### 推奨\n",
    "- 2.3.3まで（PDF82枚目まで）全て読む\n",
    "- k-NN，線形回帰，Ridge回帰，Lasso，ロジスティック回帰，サポートベクタマシン全てを実際に実行する．\n",
    "\n",
    "#### 挑戦\n",
    "- ロジスティック回帰とサポートベクタマシンの理論を調べる\n",
    "- 正規化について調べる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e491c40d",
   "metadata": {},
   "source": [
    "# 質問\n",
    "- リッジ回帰あたりからわからない"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ab2afc",
   "metadata": {},
   "source": [
    "# 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8333fc53",
   "metadata": {},
   "source": [
    "### 復習問題1\n",
    "関数を作ってください．  \n",
    "関数の引数はリストと文字，戻り値はリストだけです．  \n",
    "引数のリストは，色々な人の名前が格納されています．  \n",
    "その名前の先頭の文字が引数で与えられた文字である名前だけを取得したいです．\n",
    "\n",
    "つまり，Alive, Bobなどが与えられ，文字にAが与えられたとしたら，Aliceだけを返してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea5c883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "def select_names(names, start_char):\n",
    "    pass\n",
    "\n",
    "# テスト用\n",
    "names_list = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\", \"Ao\"]\n",
    "start_char = \"A\"\n",
    "selected_names = select_names(names_list, start_char)\n",
    "print(selected_names)  # [\"Alice\", \"Ao\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5be040",
   "metadata": {},
   "source": [
    "### 復習問題2\n",
    "特徴量が4つわかっている100人の患者がいるとします．  \n",
    "その患者が病気をもっているかどうかを分類してください．  \n",
    "k-NNを用いて分類してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6408c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 4)  # 100人の患者、4つの特徴量\n",
    "y = np.random.randint(0, 2, 100)  # 病気の有無（0または1）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286a1bb1",
   "metadata": {},
   "source": [
    "### 問題1\n",
    "以下の問題を〇か×かで答えて下さい．\n",
    "1. k-NNではモデルを事前に構築するため，新しいデータポイントの分類のための計算は比較的小さい．\n",
    "2. k-NNでは，訓練セットのサイズが大きくなると予測時間が長くなる傾向がある．\n",
    "3. k-NNは計算コストが高く大規模データセットにはあまり適しておらず，他のアルゴリズムに比べて利用頻度が低い．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa865e1",
   "metadata": {},
   "source": [
    "### 問題2\n",
    "以下の問題を〇か×かで答えて下さい．\n",
    "1. 線形回帰モデルは，データが線形関係にあるという仮定のもとで最適な予測を行う．\n",
    "2. リッジ回帰はL2正則化を用いることで，回帰係数が大きくなりすぎるのを防ぎ、モデルの過学習を抑制する．\n",
    "3. Lasso回帰はL1正則化を用いることで，不要な特徴の係数を完全にゼロにする．\n",
    "4. 線形回帰、リッジ回帰、Lasso回帰のいずれも、訓練前にデータの正規化や標準化は不必要である．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb3af9",
   "metadata": {},
   "source": [
    "### 問題3\n",
    "住宅価格の予測モデルを作成してください．  \n",
    "各住宅は特徴量5つをもっています．  \n",
    "正解値は住宅価格です．\n",
    "\n",
    "リッジ回帰を使用して回帰分析してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "001d5425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 5)  # 100住宅分の5つの特徴量\n",
    "y = np.random.rand(100) * 1000000  # 住宅価格"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c919b4",
   "metadata": {},
   "source": [
    "### 挑戦問題1\n",
    "KaggleのHouse Pricesに挑戦  \n",
    "https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques\n",
    "\n",
    "簡単なやり方\n",
    "1. アカウント作成\n",
    "2. Dataタブからcsvファイルをダウンロード\n",
    "3. ipynbファイルを作成\n",
    "4. pandasでcsvファイルをdfとして取得\n",
    "5. いらない特徴量を消去（とりあえずidや文字列の特徴量消したらお手軽）\n",
    "6. 空白のデータを埋める（平均値や中央値で埋めたらお手軽）\n",
    "7. trainデータを学習する\n",
    "8. testデータをpredictする\n",
    "9. Idとpredictした結果の2列のcsvを作成（カラム名は必要）\n",
    "10. csvファイルをKaggleにアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3ee8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
